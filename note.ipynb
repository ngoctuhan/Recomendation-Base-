{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation System là gì?\n",
    "\n",
    "Trong những năm gần đây thương mại điện tử đang có những bước phát tiến vượt bậc. Chính vì vậy những công cụ marketing mới được ra đời nhằm giới thiệu, quảng bá những sản phẩm đến đúng hơn với tập khách hàng người dùng. Chẳng hạn như chúng ta đang nghe một bài hát của Mr Siro thì sau đó Youtube đề xuất cho chúng ta hàng loạt các bài sau đó của Mr Siro, hoặc các bản nhạc có phong cách tương tự. Hay trên Shoppe khi bạn mua tả lót thì hệ thống đề xuất bạn thêm sản phẩm khác như bình sữa, khăn cho trẻ em... Một cách tổng quát tất cả chúng là ứng dụng thực tiễn của recommendation system trong cuộc sống mà chúng ta hay gặp.\n",
    "\n",
    "Vậy RS là gì?\n",
    "\n",
    "Theo Wiki: RS hay hệ thống gợi ý \"là một lớp con của hệ thống lọc thông tin, tìm kiếm dự đoán \"đánh giá\" hoặc \"ưa thích\" của nười dùng với một sản phẩm hoặc đối tượng nào đó. Hệ thống gợi ý chủ yếu dùng trong các ứng dụng thương mại\".\n",
    "\n",
    "Một cách dễ hiểu hơn RS là việc áp dụng thuật toán nhắm đưa ra khuyến nghị tốt, phù hợp với từng người dùng nhằm tạo ra giá trị marketing và ứng dụng trong thương mại điện tử."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "RS có 2 mô hình chính:\n",
    "\n",
    "   1. Collaborative filtering: hệ thống gợi ý items dựa trên sự tương quan (similarity) giữa các users và/hoặc items.Ví dụ: users A, B, C đều thích các bài hát của Noo Phước Thịnh. Ngoài ra, hệ thống biết rằng users B, C cũng thích các bài hát của Bích Phương nhưng chưa có thông tin về việc liệu user A có thích Bích Phương hay không. Dựa trên thông tin của những users tương tự là B và C, hệ thống có thể dự đoán rằng A cũng thích Bích Phương và gợi ý các bài hát của ca sĩ này tới A.\n",
    "    \n",
    "   2. Content based: đánh giá đặc tính của items được recommended cách tiếp cận này chính là việc nhóm các items lại thành các nhóm với mục đề tương tự nhau. Chẳng hạn việc xem một bộ phim về hành động thì gợi ý cho user đó thêm bộ phim hành động khác."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility matrix\n",
    "\n",
    "Một RS gồm có hai thực thể chính: user, item. Mục đích của RS là đưa đến cho user các item. Mỗi một user có một mức độ quan tâm khác nhau đến với từng item. Gỉa sử ta có mực độ quan tâm là một giá trị biểu diễn một ma trận gọi là ma trận quan tâm.\n",
    "Hàng lần lượt là các iteam còn cột là các user. Value của ma trận này thuộc miền giá trị x = [0, 5], x nguyên dương tướng ứng mức độ quan tâm cao nhất x = 5, thấp nhất là 0. Ngoài ra trường hợp x = -1 ứng việc chưa xác định được mức độ quan tâm của user đó với item.\n",
    "\n",
    "Ta có công thức giá trị ma trận được tóm tắt:\n",
    "\n",
    "$P_{ij} = k$ với $k \\in [-1,5], i \\in items, j \\in users $\n",
    "\n",
    "Càng nhiều giá trị khác -1 chứng tỏ chúng ta càng có nhiều thông tin về user, và hệ thống sẽ đề xuất càng chính xác. Tuy nhiên trong thực tế chúng ta có ít hoặc rất ít các thông tin của khác hàng mới. Vì vậy các hệ thống sẽ đề xuất theo trend hoặc theo nhu cầu của người khác.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Based Recommendations\n",
    "\n",
    "Các hệ thống RS dựa trên nội dung items, chúng ta cần xây dựng một bộ profile của item. Profile này được biểu diễn dưới dạng toán học là một feature vector.Trong những trường hợp đơn giản, feature vector được trực tiếp trích xuất từ item. Chẳng hạn một bộ phim Cung tỏa trầm hương có Profile như sau:\n",
    "1. Tên phim: Cung tỏa trầm hương\n",
    "2. Xuất xứ : Trung Quốc Đại Lục\n",
    "3. Đạo diễn: Phan An Tử\n",
    "4. Diễn viên chính: Trần Hiểu\n",
    "5. Phát hành: 2013\n",
    "6. Các nhà sản xuất: Vu Chính, Yang Du, Li Jinwen\n",
    "7. Thể loại: Cung đấu\n",
    "Trong một bộ phim có nhiều yếu tố được sử dụng nhằm khai thác tối đa các thông tin của phim. \n",
    "\n",
    "Để đơn giản nhất chúng ta sử dụng 2 thông tin của phim là mức độ cổ trang, mức độ lịch sử:\n",
    "\n",
    "![](utils_matrix.png)\n",
    "\n",
    "Một bộ phim cổ trang sẽ có tính lịch sử cao hơn bộ phim hiện đại. Gỉa sử ta có item1: bộ phim đó có mức độ cổ trang 0.99/1 và mức độ lịch sử là 0.7/1.\n",
    "\n",
    "Bài toán sẽ đi tìm một mô hình giúp cho việc xác định toàn bộ các giá trị -1 còn lại trong bảng trên. Từ đó ta dựa vào đó để đề xuất lên các item cho user sao cho iteam/user lớn nhất. Việc này tương tự như tìm một vector đặc trưng của từng người."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xây dựng hàm mất mát\n",
    "\n",
    "Gỉa sử:\n",
    "+ số users là: N\n",
    "+ số lượng items: M\n",
    "+ ma trận quan tâm: Y. Thành phần cột i, hàng i là mức độ quan tâm iteam của người i đối với item j \n",
    "+ R: là ma trận thể hiện một user đã rated(liên quan) một item hay chưa $R_{ij} = 1 $ nếu đã quan tâm, $R_{ij} = 0 $ trong trường hợp ngược lại."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Áp dụng mô hình tuyến tính cho bài toán: ( mức độ quan tâm của một user với item được biểu thị bằng một hàm tuyến tính)\n",
    "Ta có: \n",
    "##### $Y_{ij} = x_i * w_j + b_j$ ( i là hàng , j là cột) (1)\n",
    "\n",
    "$x_i$ là vector hàng, $w_j$ là vector cột.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đối với một user thứ n nếu ta coi training set là tập hợp các thành phần đã được điền của $y_n$ ta có thể xây dựng hàm mất mát tương tự như Ridge Regression (Linear Regression) như sau:\n",
    "\n",
    "Chúng ta có 2 thành phần của loss:\n",
    "1. Bình phương lỗi: $(y_{pred} - y_{true})^2 y_pred $ được tính theo công thức 1. \n",
    "2. Tham số đánh giá ma trận weight: $norm_2 (W)$ (tổng bình phương ma trận) \n",
    "\n",
    "Hàm lỗi là tổng của hai hàm trên nhân với các hệ số giúp việc giảm khối lượng tính toán.\n",
    " \n",
    "Việc làm của chúng ta là đi xác định các tham số W, b dựa trên thuật toán hạ gradient. Còn việc đạo hàm ma trận trên thì không quá khó khăn: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application \n",
    "\n",
    "Xây dựng một RS trên bộ dữ liệu Bộ cơ sở dữ liệu MovieLens 100k. Link donwload: https://grouplens.org/datasets/movielens/100k/. \n",
    "MovieLens 100k được công bố năm 1998 bởi GroupLens. Bộ cơ sở dữ liệu này bao gồm 100,000 (100k) ratings từ 943 users cho 1682 bộ phim. Các bạn cũng có thể tìm thấy các bộ cơ sở dữ liệu tương tự với khoảng 1M, 10M, 20M ratings.\n",
    "\n",
    "Sau khi download và giải nén, chúng ta sẽ thu được rất nhiều các file nhỏ, chúng ta chỉ cần quan tâm các file sau:\n",
    "\n",
    "+ u.data: Chứa toàn bộ các ratings của 943 users cho 1682 movies. Mỗi user rate ít nhất 20 movies. Thông tin về thời gian rate cũng được cho nhưng chúng ta không sử dụng trong bài viết này.\n",
    "\n",
    "+ ua.base, ua.test, ub.base, ub.test: là hai cách chia toàn bộ dữ liệu ra thành hai tập con, một cho training, một cho test. Chúng ta sẽ thực hành trên ua.base và ua.test. Bạn đọc có thể thử với cách chia dữ liệu còn lại.\n",
    "\n",
    "+ u.user: Chứa thông tin về users, bao gồm: id, tuổi, giới tính, nghề nghiệp, zipcode (vùng miền), vì những thông tin này cũng có thể ảnh hưởng tới sở thích của các users. Tuy nhiên, trong bài viết này, chúng ta sẽ không sử dụng các thông tin này, trừ thông tin về id để xác định các user khác nhau.\n",
    "\n",
    "+ u.genre: Chứa tên của 19 thể loại phim. Các thể loại bao gồm: unknown, Action, Adventure, Animation, Children's, Comedy, Crime, Documentary, Drama, Fantasy, Film-Noir, Horror, Musical, Mystery, Romance, Sci-Fi, Thriller, War, Western,\n",
    "\n",
    "+ u.item: thông tin về mỗi bộ phim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age sex  occupation zip_code\n",
       "0        1   24   M  technician    85711\n",
       "1        2   53   F       other    94043\n",
       "2        3   23   M      writer    32067\n",
       "3        4   24   M  technician    43537\n",
       "4        5   33   F       other    15213"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "#Reading user file:\n",
    "u_cols =  ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "\n",
    "# user có 5 thuộc tính: id, tuổi, giới tính, nghề nghiệp, mã khu vực\n",
    "\n",
    "users = pd.read_csv('ml-100k/u.user', sep='|', names=u_cols,encoding='latin-1')\n",
    "n_users = users.shape[0]\n",
    "print ('Number of users:', n_users)\n",
    "users.head() #uncomment this to see some few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of traing rates: 90570\n",
      "Number of test rates: 9430\n"
     ]
    }
   ],
   "source": [
    "#Reading ratings file:\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "ratings_base = pd.read_csv('ml-100k/ua.base', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "ratings_test = pd.read_csv('ml-100k/ua.test', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "\n",
    "rate_train = ratings_base.values\n",
    "rate_test = ratings_test.values\n",
    "\n",
    "print ('Number of traing rates:', rate_train.shape[0])\n",
    "print ('Number of test rates:', rate_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items: 1682\n"
     ]
    }
   ],
   "source": [
    "#Reading items file:\n",
    "i_cols = ['movie id', 'movie title' ,'release date','video release date', 'IMDb URL', 'unknown', 'Action', 'Adventure',\n",
    " 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    " 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "items = pd.read_csv('ml-100k/u.item', sep='|', names=i_cols,\n",
    " encoding='latin-1')\n",
    "\n",
    "n_items = items.shape[0]\n",
    "print ('Number of items:', n_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie id                                                              1\n",
      "movie title                                            Toy Story (1995)\n",
      "release date                                                01-Jan-1995\n",
      "video release date                                                  NaN\n",
      "IMDb URL              http://us.imdb.com/M/title-exact?Toy%20Story%2...\n",
      "unknown                                                               0\n",
      "Action                                                                0\n",
      "Adventure                                                             0\n",
      "Animation                                                             1\n",
      "Children's                                                            1\n",
      "Comedy                                                                1\n",
      "Crime                                                                 0\n",
      "Documentary                                                           0\n",
      "Drama                                                                 0\n",
      "Fantasy                                                               0\n",
      "Film-Noir                                                             0\n",
      "Horror                                                                0\n",
      "Musical                                                               0\n",
      "Mystery                                                               0\n",
      "Romance                                                               0\n",
      "Sci-Fi                                                                0\n",
      "Thriller                                                              0\n",
      "War                                                                   0\n",
      "Western                                                               0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(items.iloc[0]) # các thông tin của một bộ phim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 'Toy Story (1995)' '01-Jan-1995' nan\n",
      " 'http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)' 0 0 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# biểu diễn thông tin bộ phim thành feature vector.\n",
    "X0 = items.values\n",
    "print(X0[0])\n",
    "X_train_counts = X0[:, -19:]# chỉ lấy đặc trưng thể loại còn lại bỏ hết\n",
    "print(X_train_counts[0])\n",
    "#tfidf\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer(smooth_idf=True, norm ='l2')\n",
    "tfidf = transformer.fit_transform(X_train_counts.tolist()).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.74066017 0.57387209 0.34941857\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_items_rated_by_user(rate_matrix, user_id):\n",
    "    \"\"\"\n",
    "    in each line of rate_matrix, we have infor: user_id, item_id, rating (scores), time_stamp\n",
    "    we care about the first three values\n",
    "    return (item_ids, scores) rated by user user_id\n",
    "    \"\"\"\n",
    "    y = rate_matrix[:,0] # all users\n",
    "   \n",
    "    # item indices rated by user_id\n",
    "    # we need to +1 to user_id since in the rate_matrix, id starts from 1 \n",
    "    # while index in python starts from 0\n",
    "    ids = np.where(y == user_id +1)[0] \n",
    "\n",
    "    item_ids = rate_matrix[ids, 1] - 1 # index starts from 0 \n",
    "    scores = rate_matrix[ids, 2]\n",
    "    return (item_ids, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "\n",
    "d = tfidf.shape[1] # data dimension\n",
    "W = np.zeros((d, n_users))\n",
    "b = np.zeros((1, n_users))\n",
    "\n",
    "for n in range(n_users):    \n",
    "    ids, scores = get_items_rated_by_user(rate_train, n)\n",
    "    clf = Ridge(alpha=0.01, fit_intercept  = True)\n",
    "    Xhat = tfidf[ids, :]\n",
    "    \n",
    "    clf.fit(Xhat, scores) \n",
    "    W[:, n] = clf.coef_\n",
    "    b[0, n] = clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rated movies ids : [ 37 109 110 226 424 557 722 724 731 739]\n",
      "True ratings     : [3 3 4 3 4 3 5 3 3 4]\n",
      "Predicted ratings: [3.18 3.13 3.42 3.09 3.35 5.2  4.01 3.35 3.42 3.72]\n"
     ]
    }
   ],
   "source": [
    "# predicted scores\n",
    "Yhat = tfidf.dot(W) + b \n",
    "n = 10\n",
    "np.set_printoptions(precision=2) # 2 digits after . \n",
    "ids, scores = get_items_rated_by_user(rate_test, n)\n",
    "Yhat[n, ids]\n",
    "print('Rated movies ids :', ids )\n",
    "print('True ratings     :', scores)\n",
    "print('Predicted ratings:', Yhat[ids, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training: 0.9089804562826721\n",
      "RMSE for test    : 1.2703282700393035\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "def evaluate(Yhat, rates, W, b):\n",
    "    se = 0\n",
    "    cnt = 0\n",
    "    for n in range(n_users):\n",
    "        ids, scores_truth = get_items_rated_by_user(rates, n)\n",
    "        scores_pred = Yhat[ids, n]\n",
    "        e = scores_truth - scores_pred \n",
    "        se += (e*e).sum(axis = 0)\n",
    "        cnt += e.size \n",
    "    return math.sqrt(se/cnt)\n",
    "\n",
    "print ('RMSE for training:', evaluate(Yhat, rate_train, W, b))\n",
    "print ('RMSE for test    :', evaluate(Yhat, rate_test, W, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering\n",
    "\n",
    "Đối với một hệ đề xuất sử dụng content_base chúng ta chỉ mới sử dụng các thông tin là các đặc trưng của các items mà bỏ qua thông tin của các user. Trên thực tế việc tận dụng thông tin từ người dùng, nhóm người dùng chúng ta có thể cung cấp ra được nhưng sản phẩm chính xác, và việc nắm bắt hành vi của user cung cấp cho người phát triển thông tin tối đa hóa nhu cầu các nhân của từng user để có một hệ đề xuất chính xác. Chính về điều đó mà phương pháp Collaborative Filtering ra đời nhằm giải quyết điểm yếu của CB. Có 2 thuật toán CF điển hình là:\n",
    "\n",
    "+ Neighborhood-based Collaborative Filtering\n",
    "+ Matrix Factorization Collaborative Filtering\n",
    "\n",
    "Khi chỉ nói Collaborative Filtering, chúng ta sẽ ngầm hiểu rằng phương pháp được sử dụng là Neighborhood-based.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neighborhood-based Collaborative Filtering (NBCF)\n",
    "\n",
    "Ý tưởng cơ bản của NBCF là xác định mức độ quan tâm của một user tới một item dựa trên các users khác gần giống với user này. Việc gần giống nhau giữa các users có thể được xác định thông qua mức độ quan tâm của các users này tới các items khác mà hệ thống đã biết. Ví dụ, A, B đều thích phim Cảnh sát hình sự, tức đều rate bộ phim này 5 sao. Ta đã biết A cũng thích Người phán xử, vậy nhiều khả năng B cũng thích bộ phim này.\n",
    "\n",
    "Hai vấn đề cần giải quyết trong NBCF?\n",
    "+ Làm thế nào xác định được sự giống nhau giữa hai users?\n",
    "+ Khi đã xác định được các users gần giống nhau (similar users) rồi, làm thế nào dự đoán được mức độ quan tâm của một user lên một item?\n",
    "\n",
    "Việc xác định mức độ quan tâm của mỗi user tới một item dựa trên mức độ quan tâm của similar users tới item đó còn được gọi là User-user collaborative filtering. Có một hướng tiếp cận khác được cho là làm việc hiệu quả hơn là Item-item collaborative filtering. Trong hướng tiếp cận này, thay vì xác định user similarities, hệ thống sẽ xác định item similarities. Từ đó, hệ thống gợi ý những items gần giống với những items mà user có mức độ quan tâm cao."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. User-user Collaborative Filtering\n",
    "\n",
    "Với phương pháp này việc quan trọng chúng ta phải xác định sự tương giống nhau giữa các user. \n",
    "\n",
    "![](utils_matrix.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theo một cách trực quan ta thấy u1 giống u2 hơn là giống u3, u4, u5. Và u3 có vẻ giống u4 hơn là u1, u4, u5.  \n",
    "u1 và u2 là tương giống nhau mà ta thấy rằng u1 thích i3 nên có thể đề xuất cho u2 có thể quan tâm đến i3. \n",
    "\n",
    "Đến đây thì một vấn đề lớn đặt ra: Vậy làm sao để có thể xác định được hàm similarity độ giống nhau của hai user (kí hiệu sim(u1,u2) )\n",
    "\n",
    "Cách thông thường là xây dựng feature vector cho từng user. Trên thực tế thông tin ta có của user nằm trong Utility matrix tuy nhiên thường user sẽ có nhiều giá trị chứ xác định một cách nào đó phải điều (fill) các giá trị này sao cho việc tính toán similarity của hai user sẽ không bị ảnh hưởng. Việc điền này chỉ phục vụ cho việc tính similarity chứ không phải là suy luận ra giá trị cuối cùng.\n",
    "\n",
    "Suy luận bạn đầu: thay các giá trị ? bằng số 0. Điều này cũng không hẳn chính xác vì 0 đại diện cho mức độ quan tâm thấp nhất. Một giá trị an toàn hơn là 2.5 vì nó là trung bình cộng của 0, mức thấp nhất, và 5, mức cao nhất. Tuy nhiên, giá trị này có hạn chế đối với những users dễ tính hoặc khó tính. Với các users dễ tính, thích tương ứng với 5 sao, không thích có thể ít sao hơn 1 chút, 3 sao chẳng hạn. Việc chọn giá trị 2.5 sẽ khiến cho các items còn lại là quá negative đối với user đó. Điều ngược lại xảy ra với những user khó tính hơn khi chỉ cho 3 sao cho các items họ thích và ít sao hơn cho những items họ không thích.\n",
    "\n",
    "Một giá trị khả dĩ hơn cho việc này là trung bình cộng của các ratings mà user tương ứng đã thực hiện. Việc này sẽ tránh được việc users quá khó tính hoặc dễ tính, tức lúc nào cũng có những items mà một user thích hơn so với những items khác.\n",
    "\n",
    "Chuẩn hoá dữ liệu:\n",
    "\n",
    "\"Hàng cuối cùng trong Hình 2a) là giá trị trung bình của ratings cho mỗi user. Giá trị cao tương ứng với các user dễ tính và ngược lại. Khi đó, nếu tiếp tục trừ từ mỗi rating đi giá trị này và thay các giá trị chưa biết bằng 0, ta sẽ được normalized utility matrix như trong Hình 2b). Bạn có thể thắc mắc tại sao bước chuẩn hoá này lại quan trọng, câu trả lời ở ngay đây:\n",
    "\n",
    "Việc trừ đi trung bình cộng của mỗi cột khiến trong trong mỗi cột có những giá trị dương và âm. Những giá trị dương tương ứng với việc user thích item, những giá trị âm tương ứng với việc user không thích item. Những giá trị bằng 0 tương ứng với việc chưa xác định được liệu user có thích item hay không.\n",
    "Về mặt kỹ thuật, số chiều của utility matrix là rất lớn với hàng triệu users và items, nếu lưu toàn bộ các giá trị này trong một ma trận thì khả năng cao là sẽ không đủ bộ nhớ. Quan sát thấy rằng vì số lượng ratings biết trước thường là một số rất nhỏ so với kích thước của utility matrix, sẽ tốt hơn nếu chúng ta lưu ma trận này dưới dạng sparse matrix, tức chỉ lưu các giá trị khác không và vị trí của chúng. Vì vậy, tốt hơn hết, các dấu ‘?’ nên được thay bằng giá trị ‘0’, tức chưa xác định liệu user có thích item hay không. Việc này không những tối ưu bộ nhớ mà việc tính toán similarity matrix sau này cũng hiệu quả hơn.\" (https://machinelearningcoban.com/2017/05/24/collaborativefiltering/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các bước thực hiện như sau:\n",
    "\n",
    "1. Tính avg rate item của từng user\n",
    "2. Điều các chỗ trống là 0, các giá trị khác trừ đi giá trị TB ( giải thích bên trên)\n",
    "\n",
    "Kết quả bước 1 và bước 2 được hiển thị trong ảnh\n",
    "\n",
    "![](fill.png)\n",
    "\n",
    "3. Áp dụng các hàm similary thông dụng để tính ma trận user-similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cos Similarity (công thức tính cos của góc giữa hai vector u1,u2):\n",
    "\n",
    "#### $cos(u_1, u_2) = \\frac{{u_1}^T . u_2} {|u_1||u_2|}$\n",
    "\n",
    "Trong đó: u1, u2 là hai vector đặc trưng của 2 user được lấy ra từ bảng trên.\n",
    "Độ similarity của hai vector là 1 số trong đoạn [-1, 1]. Giá trị bằng 1 thể hiện hai vector hoàn toàn similar nhau. Hàm số cos của một góc bằng 1 nghĩa là góc giữa hai vector bằng 0, tức một vector bằng tích của một số dương với vector còn lại. Giá trị cos bằng -1 thể hiện hai vector này hoàn toàn trái ngược nhau. Điều này cũng hợp lý , tức khi hành vi của hai users là hoàn toàn ngược nhau thi similarity giữa hai vector đó là thấp nhất.\n",
    "\n",
    "Kết quả tính toán ta được ma trận ( sử dụng python tính toán): \n",
    "\n",
    "![](user_similary.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.2   0.    1.1  -0.8  -0.8  -1.8 ]\n",
      " [ 0.5   0.    0.    2.   -0.5  -0.5 ]\n",
      " [ 0.    0.    0.    0.   -2.   -2.  ]\n",
      " [ 0.    0.   -2.75  1.25  1.25  0.25]\n",
      " [-2.   -1.    0.    1.    2.    0.  ]]\n",
      "---------------------------------------\n",
      "\n",
      "[[ 1.          0.11290305  0.5654847  -0.51362056 -0.66141101]\n",
      " [ 0.11290305  1.          0.32444284  0.244899    0.        ]\n",
      " [ 0.5654847   0.32444284  1.         -0.32349832 -0.4472136 ]\n",
      " [-0.51362056  0.244899   -0.32349832  1.          0.36168212]\n",
      " [-0.66141101  0.         -0.4472136   0.36168212  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "users =  np.array([[2.2, 0, 1.1, -0.8, -0.8, -1.8], \n",
    "                  [0.5,0,0,2,-0.5, -0.5], \n",
    "                  [0, 0, 0, 0, -2, -2],\n",
    "                  [0, 0, -2.75, 1.25, 1.25, 0.25],\n",
    "                  [-2,-1, 0, 1, 2, 0]])\n",
    "print(users)\n",
    "print(\"---------------------------------------\\n\")\n",
    "result = np.ones((5, 5))\n",
    "for i in range(users.shape[0]):\n",
    "    user1 = users[i]\n",
    "    for j in range(i, users.shape[0]):\n",
    "        user2 =  users[j]\n",
    "        cos =  cosine_similarity([user1], [user2])\n",
    "        result[i][j] = cos[0][0]\n",
    "        result[j][i] = cos[0][0]  \n",
    "print(result)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Sau khi tính toán được ma trận tương tự các user. Bước tiếp theo là Predict rated.\n",
    "\n",
    "Trong ví dụ trên ta dự đoán rate của u2 và i3:\n",
    "Ta thấy các user quan tâm đến i3 là: u1, u4. Similary của u2 với các user này là: 0.11 và 0.25. Normalized ratings của u1, u4 là: 1.1 và -2.75\n",
    "Tương tự như thuật toán KNN thì người hàng xóm gần nhất với u2 là u4. Trong TH này sử dụng k = 2 thì 2 người hàng xóm gần nhất với u2 được sử dụng làm căn cứ đề xuất cho u2.\n",
    "\n",
    "Ta có kết quả dự đoán rate của u2 và i3 được tính toán theo công thức:\n",
    "\n",
    "#### $\\hat{y}_{i, u} = \\frac{\\sum_{u_j \\in \\mathcal{N}(u, i)} \\bar{y}_{i, u_j} \\text{sim}(u, u_j)}{\\sum_{u_j \\in \\mathcal{N}(u, i)} |\\text{sim}(u, u_j)|} $\n",
    "\n",
    "Vậy ta có:\n",
    "### y_pred = $\\frac{0.11 * 1.1 + 0.25 * (-2.75)}{|1.1| + |-2.75|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pearson correlation coefficient\n",
    "\n",
    "Tham khảo thêm tại: https://en.wikipedia.org/wiki/Pearson_correlation_coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Item-item Collaborative Filtering\n",
    "\n",
    "Cùng tương tự user-user collaborative Filtering, IICF tính toán similary của các item nhờ đó sẽ đề xuất ra cho user các sản phẩm tương tự với các item đã biết. Phương pháp này giải quyết được các hạn chế của UUCF:\n",
    "\n",
    "+ Trên thực tế, số lượng users luôn lớn hơn số lượng items rất nhiều. Kéo theo đó là Similarity matrix là rất lớn với số phần tử phải lưu giữ là hơn 1 nửa của bình phương số lượng users (chú ý rằng ma trận này là đối xứng). Việc này, như đã đề cập ở trên, khiến cho việc lưu trữ ma trận này trong nhiều trường hợp là không khả thi.\n",
    "\n",
    "+ Ma trận Utility Y thường là rất sparse. Với số lượng users rất lớn so với số lượng items, rất nhiều cột của ma trận này sẽ rất sparse, tức chỉ có một vài phần tử khác 0. Lý do là users thường lười rating. Cũng chính vì việc này, một khi user đó thay đổi rating hoặc rate thêm items, trung bình cộng các ratings cũng như vector chuẩn hoá tương ứng với user này thay đổi nhiều. Kéo theo đó, việc tính toán ma trận Similarity, vốn tốn nhiều bộ nhớ và thời gian, cũng cần được thực hiện lại.\n",
    "\n",
    "Ngược lại, nếu chúng ta tính toán similarity giữa các items rồi recommend những items gần giống với item yêu thích của một user thì sẽ có những lợi ích sau:\n",
    "\n",
    "+ Vì số lượng items thường nhỏ hơn số lượng users, Similarity matrix trong trường hợp này cũng nhỏ hơn nhiều, thuận lợi cho việc lưu trữ và tính toán ở các bước sau.\n",
    "\n",
    "+ Vì số lượng phần tử đã biết trong Utility matrix là như nhau nhưng số hàng (items) ít hơn số cột (users), nên trung bình, mỗi hàng của ma trận này sẽ có nhiều phần tử đã biết hơn số phần tử đã biết trong mỗi cột. Việc này cũng dễ hiểu vì mỗi item có thể được rated bởi nhiều users. Kéo theo đó, giá trị trung bình của mỗi hàng ít bị thay đổi hơn khi có thêm một vài ratings. Như vậy, việc cập nhật ma trận Similarity Matrix có thể được thực hiện ít thường xuyên hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Factorization Collaborative Filtering (MFCF)\n",
    "\n",
    "Trong phương pháp này mỗi item được đặc trưng một vector x gọi là item profile. Gỉa sử mỗi user ta tìm được một vetor w mà cho rating đã biết mà user đó cho item xấp xỉ với:\n",
    "\n",
    "y ~ wx\n",
    "\n",
    "W tương tự ma trận trọng số\n",
    "X là ma trận đặc trưng của từng item\n",
    "\n",
    "Điều này giúp ta vận dụng việc huấn luyện phức tạp ( deep learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
